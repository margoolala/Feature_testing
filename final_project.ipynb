{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL PROJECT. Решение комплексной бизнес-задачи. Создание рекомендательной системы курсов для онлайн-школы MasterMind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Цель : подготовить основу рекомендательной системы, благодаря которой можно будет предлагать клиентам интересные им курсы и тем самым повышать средний чек."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формализованные задачи: \n",
    "- Подготовить и проанализировать данные с помощью SQL\n",
    "- Обработать данные средствами Python\n",
    "- Составить итоговую таблицу с рекомендациями, снабдив её необходимыми комментариями\n",
    "- Протестировать фичу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая таблица должна состоять из трёх столбцов:\n",
    "- 1.Курс, к которому идёт рекомендация.\n",
    "- 2.Курс для рекомендации № 1 (самый популярный).\n",
    "- 3.Курс для рекомендации № 2 (второй по популярности).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import psycopg2.extras \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим функцию, которая выполнит SQL-запрос:\n",
    "# Получающий данные по продажам курсов в разрезе пользователей \n",
    "def getCourseUsers():\n",
    "    query = '''WITH relevant_clients as (\n",
    "    SELECT DISTINCT user_id,\n",
    "      COUNT(DISTINCT ci.resource_id) quantity\n",
    "    FROM final.carts c\n",
    "    JOIN final.cart_items ci ON c.id = ci.cart_id\n",
    "    WHERE state = 'successful' AND resource_type = 'Course'\n",
    "    GROUP BY 1\n",
    "    HAVING COUNT(DISTINCT ci.resource_id) > 1)\n",
    "\n",
    "    SELECT DISTINCT c.user_id,\n",
    "       ci.resource_id\n",
    "    FROM relevant_clients rc \n",
    "    JOIN final.carts c ON rc.user_id = c.user_id\n",
    "    JOIN final.cart_items ci ON c.id = ci.cart_id\n",
    "    WHERE state = 'successful' AND resource_type = 'Course'\n",
    "    '''.format()\n",
    "    conn = psycopg2.connect(\"dbname='skillfactory' user='skillfactory' host='84.201.134.129' password='cCkxxLVrDE8EbvjueeMedPKt' port=5432\")\n",
    "    dict_cur = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)\n",
    "    dict_cur.execute(query)\n",
    "    rows = dict_cur.fetchall()\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        data.append(dict(row))\n",
    "    return data\n",
    "# Выполним функцию запроса и запишем полученные данные в датафрейм\n",
    "client_course_df = pd.DataFrame(getCourseUsers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>resource_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909757</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>583850</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1559882</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>970967</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1640443</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  resource_id\n",
       "0   909757          356\n",
       "1   583850          515\n",
       "2  1559882          566\n",
       "3   970967          679\n",
       "4  1640443          566"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_course_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12656"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подсчитаем кол-во уникальнх пользователей\n",
    "client_course_df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датафрейм содержит данные о 12656 уникальных пользователях, купивших более 1 курса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим датафрейм со списком всех купленных курсов для каждого пользователя\n",
    "course_pivot = client_course_df.groupby('user_id')['resource_id'].apply(lambda x: x.tolist()).reset_index()\n",
    "# Отсортируем получившиеся списки\n",
    "course_pivot['resource_id'] = course_pivot['resource_id'].apply(lambda x: sorted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобъем все покупки пользователей по парам со всеми возможными комбинациями\n",
    "# Используем функцию combinations, чтобы избежать зеркальных пар\n",
    "from itertools import combinations\n",
    "course_pair_list = []\n",
    "for i in course_pivot['resource_id']:\n",
    "    for pair_id in combinations(i,2):\n",
    "        course_pair_list.append(pair_id)\n",
    "# Ранжируем полученные пары по частности совместных продаж посредством counter и запишем все в словарь отсортированный по убыванию\n",
    "from collections import Counter\n",
    "range_pairs = dict(Counter(course_pair_list).most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление таблицы рекомендаций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как составить рекомендации, необходимо определить минимальную границу по частоте совместных покупок курсов, т.е. отсечь случайные. Для этого создадим временный датафрейм из значений словаря 'range_pairs' для оценки статистики выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3989.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.031838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.355998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>797.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sales_quantity\n",
       "count     3989.000000\n",
       "mean        10.031838\n",
       "std         26.355998\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          3.000000\n",
       "75%          9.000000\n",
       "max        797.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict = pd.DataFrame(data= range_pairs.values(),columns=['sales_quantity'])\n",
    "df_dict.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описательная статистика показывает большой разброс значений со стандартным отклонением в 26,35, значит будем использовать более широкий доверительный интервал равный 95%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Найдем нижнюю границу для случайных значений выборки\n",
    "lower_border = int(df_dict.quantile(q=0.95))\n",
    "round(lower_border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим функцию, которая будет на вход принимать id курса и подбирать для него 2 рекомендации из словаря range_pairs \n",
    "def recommendation(id):\n",
    "    recommend_list = []\n",
    "    for i in range_pairs.keys():\n",
    "# Если значение id найдено в паре и ранг пары больше установленной границы частности, добавлять соответствующее ему второе значение в список\n",
    "        if i[0] == id and range_pairs[i] > lower_border:\n",
    "            recommend_list.append(i[1])\n",
    "        elif i[1] == id  and range_pairs[i] > lower_border:\n",
    "            recommend_list.append(i[0])\n",
    "# Оставим только 2 самых часто встречающихся значения\n",
    "    return recommend_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим список уникальных id курсов\n",
    "uniq_id_list = list(client_course_df.resource_id.unique())\n",
    "\n",
    "# Создадим датафрейм-основу рекоммендательной таблицы\n",
    "course_recommend_df = pd.DataFrame(columns=['Course','1_st_recommendation','2_nd_recommendation'])\n",
    "\n",
    "# Запустим цикл по списку с уникальными id, которым будут через функцию recommendation подбираться рекомендации\n",
    "# Из-за нижней границы ранга не всем курсам подберется по две рекоммендации, недостающие значения заместим на nan\n",
    "for i in uniq_id_list:\n",
    "    if len(recommendation(i)) == 2:\n",
    "        course_recommend_df.loc[i] = [i, recommendation(i)[0], recommendation(i)[1]]\n",
    "    elif len(recommendation(i)) == 1:\n",
    "        course_recommend_df.loc[i] = [i, recommendation(i)[0], np.nan]\n",
    "    else:\n",
    "        course_recommend_df.loc[i] = [i, np.nan, np.nan]\n",
    "course_recommend_df = course_recommend_df.sort_values(['Course']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Course               126 non-null    float64\n",
      " 1   1_st_recommendation  63 non-null     float64\n",
      " 2   2_nd_recommendation  51 non-null     float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 3.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим полученный датафрейм\n",
    "course_recommend_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замену позиций с NaN будем осуществлять следующим образом: \n",
    "- если подобралась только 1-ая рекомендация, то 2-ая рекомендация будет из списка рекомендаций, который подобрался для 1-ой, чтобы сохранить алгоритм совместных частых покупок\n",
    "- если же к курсу не подобралось ни одной рекомендации, то будем заменять на наши самые продаваемые курсы, кроме 1-ого самого  популярного, так как скорее всего о платформе узнали как раз из-за него, а мы не хотим быть платформой одного курса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[566, 515]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Найдем топ-2 самых продаваемых курса, помимо первого \n",
    "# Для этого воспользуемся изначальным выгруженным датафреймом и подсчитаем частоту покупок каждого курса\n",
    "top_2 = list(client_course_df.resource_id.value_counts().index)[1:3]\n",
    "top_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем замену значений NaN по вышеописанному алгоритму\n",
    "# Заменим значения для курсов, не получивших ни одной рекомендации\n",
    "course_recommend_df.loc[((course_recommend_df['1_st_recommendation'].isna()) & (course_recommend_df['2_nd_recommendation'].isna())), \\\n",
    "    ('1_st_recommendation','2_nd_recommendation')] = 566,515\n",
    "# Заменим значения для курсов с одной рекоммендацией\n",
    "for i in course_recommend_df.index:\n",
    "# Если значение nan, то заменить  на рекомедацию для 1-ого подобранного курса    \n",
    "    if np.isnan(course_recommend_df.loc[i,'2_nd_recommendation']):\n",
    "        course_recommend_df.loc[i,'2_nd_recommendation'] = recommendation(course_recommend_df.loc[i,'1_st_recommendation'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Course               126 non-null    float64\n",
      " 1   1_st_recommendation  126 non-null    float64\n",
      " 2   2_nd_recommendation  126 non-null    float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 3.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Проверим целостность заполнения таблицы\n",
    "course_recommend_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем датафрейм в файл \n",
    "course_recommend_df.to_csv('course_recommend.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый из вариантов A/B-теста достиг необходимого размера выборки, и теперь необходимо сделать вывод, можно ли считать реализацию рекомендательной системы успешной, и принять решение о полезности её внедрения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Численное выражение полученных результатов таково:\n",
    "- В контрольной группе оказалось 8732 клиента, оформивших заказ, из них 293 купили больше одного курса.\n",
    "- В тестовой — 8847 клиентов, из них 347 купили больше одного курса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_group = 8732\n",
    "b_group = 8847\n",
    "relation = a_group/b_group\n",
    "round(relation,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжаем тест, так как разница не превышает 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats as st\n",
    "import math as mth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гипотезы:\n",
    "- Н0: Конверсии обеих групп равны\n",
    "- Н1: Конверсии группы В > A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value равен 0.02243159896524971\n"
     ]
    }
   ],
   "source": [
    "# Задаём желаемый уровень статистической значимости: \n",
    "a = .05\n",
    "x_A = 293\n",
    "x_B = 347\n",
    "n_A = a_group\n",
    "n_B = b_group\n",
    "p_A = x_A / n_A\n",
    "p_B = x_B / n_B\n",
    "p = (x_A + x_B) / (n_A + n_B)\n",
    "# Посчитаем разницу в пропорциях: \n",
    "diff = p_A - p_B\n",
    "# Рассчитаем Z-статистику:\n",
    "z = diff / mth.sqrt(p * (1 - p) * (1/n_A + 1/n_B))\n",
    "# Зададим нормальное стандартное распределение со средним, равным нулю, и стандартным отклонением, равным единице:\n",
    "distr = st.norm(0, 1)\n",
    "# Рассчитаем p-value, примепним односторонний тест :\n",
    "z_p_val = (1 - distr.cdf(abs(z)))\n",
    "print('P-value равен', z_p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-value меньше принятого уровня значимости, следовательно, нулевая гипотеза не оправдалась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конверсия группы b (3.92%) была на 16.6% выше чем конверсия группы a (3.36%). С вероятностью 95% можно быть уверенным, что полученнй результат конверсии был достигнут благодаря введению новой фичи, а не случайностью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице представлено 126 курсов (всего у нас есть данные о 127 курсах, но один из курсов не попал в выборку, т.к. нет данных по его покупке) с рекомендациями, которые опираются на частоту совместных покупок пар курсов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нижняя граница частоты совместных покупок с  95% доверительным интервалом  должна быть больше 37 раз, все пары курсы купленные реже нижней границы приняты случайными и не использовались."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом используя данный алгоритм удалось заполнить 50% таблицы, еще 50% таблицы заполнили рекомендуя курсы, которые покупали вместе с одним из уже предложенных, а для курсов, которым не нашлось ни одной рекомендации изначально, предложили наши топ-2 и топ-3 самых продаваемых курса ( так как топ-1 итак достаточно популярный и не нуждается в рекламе)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование показало: вариант с рекомендациями показал статистически значимо лучший результат, нужно реализовывать его для всех клиентов. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
